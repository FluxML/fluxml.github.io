<!DOCTYPE html> <html lang=en > <style> #cppn{ position:absolute; top:0; bottom:0; height: 100%; width: 100vw; } iframe { display: block; border-style:none; } </style> <meta property="og:title" content=Flux.jl > <meta property="og:description" content="The elegant machine learning library"> <meta property="og:image" content="/assets/images/FluxGitHubPreview.png"> <meta property="og:url" content=fluxml.ai > <meta name="twitter:title" content=Flux.jl > <meta name="twitter:description" content="The elegant machine learning library"> <meta name="twitter:image" content="/assets/images/FluxGitHubPreview.png"> <meta name="twitter:card" content=summary_large_image > <link rel=apple-touch-icon  sizes=180x180  href="assets/favicon_io/apple-touch-icon.png"> <link rel=icon  type="image/png" sizes=32x32  href="assets/favicon_io/favicon-32x32.png"> <link rel=icon  type="image/png" sizes=16x16  href="assets/favicon_io/favicon-16x16.png"> <link rel=manifest  href="assets/favicon_io/site.webmanifest"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-36890222-9"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-36890222-9'); </script> <meta charset=utf-8 > <meta name=viewport  content="width=device-width, initial-scale=1, shrink-to-fit=no"> <link rel=stylesheet  href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin=anonymous > <link rel=stylesheet  href="../css/script_default.css"> <link rel=stylesheet  href="../css/site.css"> <link rel=stylesheet  href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin=anonymous > <link rel=stylesheet  href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin=anonymous > <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin=anonymous ></script> <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin=anonymous  onload="renderMathInElement(document.body, { delimiters: [ {left: '$[[', right: ']]', display: true}, {left: '\\[', right: '\\]', display: true}, {left: '[[', right: ']]', display: false} ] });"> </script> <title>Flux â€“ Elegant ML</title> <nav class="navbar navbar-expand-lg navbar-dark container lighter"> <a class=navbar-brand  href="/./"> <div class=logo  style="font-size:30pt;margin-top:-15px;margin-bottom:-10px;">flux</div> </a> <button class=navbar-toggler  type=button  data-toggle=collapse  data-target="#navbarSupportedContent" aria-controls=navbarSupportedContent  aria-expanded=false  aria-label="Toggle navigation"> <span class=navbar-toggler-icon ></span> </button> <div class="collapse navbar-collapse" id=navbarSupportedContent > <ul class="navbar-nav mr-auto"> <li class=nav-item > <a class=nav-link  href="https://fluxml.ai/Flux.jl/" target=_blank >Documentation</a> <li class=nav-item > <a class=nav-link  href="https://github.com/FluxML/model-zoo/" target=_blank >Model Zoo</a> <li class=nav-item > <a class=nav-link  href="https://github.com/FluxML/Flux.jl" target=_blank >GitHub</a> <li class=nav-item > <a class=nav-link  href="https://fluxml.ai/Flux.jl/stable/ecosystem/">Ecosystem</a> <!-- <li class=nav-item > <a class=nav-link  href="/./gsod/">GSoD</a> --> <li class=nav-item > <a class=nav-link  href="/./blog/">Blog</a> <li class=nav-item > <a class=nav-link  href="/./gsoc/">GSoC</a> <li> <a class=nav-link  href="/./governance/">Governance</a> <li class=nav-item > <a class=nav-link  href="https://github.com/FluxML/Flux.jl/blob/master/CONTRIBUTING.md" target=_blank >Contribute</a> </ul> </div> </nav> <div class=content > <div class=container > <div class=franklin-content > <h1>FluxML Projects - Summer of Code</h1> <p>Flux usually takes part in <a href="https://summerofcode.withgoogle.com">Google Summer of Code</a> as a NumFocus organization. We follow the same <a href="https://julialang.org/jsoc/projects/">rules and application guidelines</a> as Julia, so please check there for more information on applying. Below are a set of ideas for potential projects &#40;though you are welcome to explore anything you are interested in&#41;. <strong>Please note that year for the idea list. Project ideas from a previous year will not always carry over to a new year.</strong></p> <p>Flux projects are typically very competitive; we encourage you to get started early, as successful contributors typically have early PRs or working prototypes as part of the application. It is a good idea to simply start contributing via issue discussion and PRs and let a project grow from there; you can take a look at <a href="https://github.com/FluxML/Flux.jl/issues?q&#61;is&#37;3Aopen&#43;is&#37;3Aissue&#43;label&#37;3A&#37;22help&#43;wanted&#37;22">this list of issues</a> for some starter contributions. Please see the <a href="https://github.com/FluxML/Flux.jl/blob/master/CONTRIBUTING.md">contributing guide</a> for help first.</p> <h1 id=fluxml_gsoc_2023_ideas_list ><a href="#fluxml_gsoc_2023_ideas_list" class=header-anchor >FluxML GSoC 2023 Ideas List</a></h1> <h2 id=writing_julia-native_kernels_for_common_nn_operations ><a href="#writing_julia-native_kernels_for_common_nn_operations" class=header-anchor >Writing Julia-native kernels for common NN operations</a></h2> <p>Implement optimized kernels for common neural network operations for which we don&#39;t already have Julia-native implementations. This project will require experience with GPU kernel writing and performance optimizations.</p> <p><strong>Difficulty.</strong> Hard. <strong>Duration.</strong> 350 hours</p> <h3 id=description ><a href="#description" class=header-anchor >Description</a></h3> <p>Many ML frameworks are making the move away from vendor-specific libraries &#40;like CUBLAS, CUDNN, etc.&#41; towards more generic, JIT-compiled implementations of ML-related kernels, like BLAS, softmax, ReLU, etc. The reasons for this move are many-fold:</p> <ul> <li><p>Vendor-provided libraries often only work on that vendor&#39;s hardware and software</p> <li><p>These libraries only support certain element types, tensor shapes/sizes, and limited array view/stride/transpose support</p> <li><p>These libraries often expect to be executed from the host, without a device-side launchable equivalent</p> <li><p>These libraries have unreliable build systems or are binary blobs</p> </ul> <p>Improving this state of affairs for Flux will involve using Julia&#39;s existing GPU and compute kernel libraries &#40;e.g KernelAbstractions.jl&#41; to implement various accelerated, cross-vendor routines. These kernels should be both composable and performance competitive with Flux&#39;s current generic code paths. Examples of routines specifically useful for implementing Neural Networks include:</p> <ul> <li><p>GEMM and GEMV</p> <li><p>Softmax</p> <li><p>Batchnorm and Layernorm</p> <li><p>ReLU</p> <li><p>Convolution/correlation</p> </ul> <p>The ideal candidate should have experience with what operations are used in popular ML models and how they are commonly implemented on GPU. This includes experience writing and benchmarking high performance GPU kernels. Because kernels will be required for both training and inference, an understanding of automatic differentiation &#40;AD&#41; is also highly recommended.</p> <p><strong>Mentors.</strong> <a href="https://github.com/jpsamaroo">Julian Samaroo</a>, <a href="https://github.com/darsnack">Kyle Daruwalla</a>, <a href="https://github.com/ToucheSir">Brian Chen</a></p> <h3 id=prerequisites ><a href="#prerequisites" class=header-anchor >Prerequisites</a></h3> <ul> <li><p>Julia language fluency is essential.</p> <li><p>Experience with low-level GPU kernel programming is strongly recommended.</p> <li><p>Experience with common primitive machine learning ops &#40;forwards and backwards passes&#41; and their interaction is recommended.</p> <li><p>Familiarity with existing prior art such as <a href="https://github.com/NVlabs/tiny-cuda-nn">tiny-cuda-nn</a> is preferred.</p> </ul> <h3 id=your_contributions ><a href="#your_contributions" class=header-anchor >Your contributions</a></h3> <ul> <li><p>A new package containing the optimized kernels and any supporting code for integration into Flux/Flux&#39;s operation library <a href="https://github.com/FluxML/NNlib.jl">NNlib.jl</a>.</p> <li><p>Tests on CI and a simple benchmark harness for the new NN kernel library.</p> <li><p>A proof-of-concept example showing the kernels being used with kernel fusion on device &#40;GPU&#41;.</p> </ul> <h2 id=benchmark_tooling_for_common_models_and_operations ><a href="#benchmark_tooling_for_common_models_and_operations" class=header-anchor >Benchmark tooling for common models and operations</a></h2> <p>Create a benchmarking tool for the FluxML ecosystem that we can invoke on demand from PRs. This project will require previous experience with training machine learning models at a &quot;low-level&quot; &#40;i.e. without the use of tools like PyTorch Lightning&#41;.</p> <p><strong>Difficulty.</strong> Moderate. <strong>Duration.</strong> 350 hours</p> <h3 id=description__2 ><a href="#description__2" class=header-anchor >Description</a></h3> <p>FluxML&#39;s machine learning stack is distributed across many packages, and each package is designed to function as independently as possible. This is done to maximize code-reuse across the Julia ML ecosystem. As a result, it is challenging for us to quantitively determine the performance impact of code changes without manual testing. The goal of this project is to develop a FluxML-specific benchmarking package. The package should allow us to install specific commits of various packages across the FluxML stack, then run a benchmarking suite. The test suite will include low-level operations like convolution or simple gradient calls, as well as complete end-to-end examples like a full forward/backward pass of Metalhead.jl models. </p> <p>The ideal candidate should have experience with multiple ML task setups such as vision, autoregressive language modeling, time series forecasting, etc. Furthermore, some experience with Github Actions and continuous integration &#40;CI&#41; is suggested.</p> <p><strong>Mentors.</strong> <a href="https://github.com/ToucheSir">Brian Chen</a>, <a href="https://github.com/darsnack">Kyle Daruwalla</a></p> <h3 id=prerequisites__2 ><a href="#prerequisites__2" class=header-anchor >Prerequisites</a></h3> <ul> <li><p>Julia language fluency is essential.</p> <li><p>Github CI and experience with GH Actions is strongly suggested.</p> <li><p>Experience with more than one ML task &#40;e.g. image classification, autoregressive language modeling, etc.&#41;.</p> <li><p>Familiarity with prior art is preferred:</p> <ul> <li><p><a href="https://github.com/tkf/BenchmarkCI.jl">BenchmarkCI.jl</a></p> <li><p><a href="https://speed.juliagpu.org">JuliaGPU speed center</a></p> <li><p><a href="https://benchmark.tansongchen.com/TaylorDiff.jl">TaylorDiff benchmarking site</a></p> </ul> </ul> <h3 id=your_contributions__2 ><a href="#your_contributions__2" class=header-anchor >Your contributions</a></h3> <ul> <li><p>A new FluxML package, FluxBenchmarks.jl, that will perform configurable benchmarking across our ML stack.</p> <li><p>Github Actions integration for FluxBenchmarks.jl to invoke the tool from PRs.</p> <li><p>A benchmarking suite that will build your experience with different types of ML models and operations across the stack.</p> </ul> </div> </div> </div> <div class="container footer lighter"> <p>Flux: A Deep Learning Library for the Julia Programming Language </p> <a href="https://twitter.com/FluxML?ref_src=twsrc%5Etfw" class=twitter-follow-button  data-show-count=false >Follow @FluxML</a> <script async src="https://platform.twitter.com/widgets.js" charset=utf-8 ></script> </div> <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script> <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script> <script src="/./libs/highlight.pack.js"></script> <script>hljs.initHighlightingOnLoad();</script> <script src="/.//instant.page/1.0.0" type=module  integrity="sha384-6w2SekMzCkuMQ9sEbq0cLviD/yR2HfA/+ekmKiBnFlsoSvb/VmQFSi/umVShadQI"></script>